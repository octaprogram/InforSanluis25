{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8dde2aa9-f33e-4e4e-bf5b-9d3521207d20",
      "metadata": {
        "id": "8dde2aa9-f33e-4e4e-bf5b-9d3521207d20"
      },
      "source": [
        "<div align=\"right\"><i>Mat√≠as Torres Esteban<br>Diciembre, 2025</i></div>\n",
        "\n",
        "# Interpretaci√≥n de Textos con LLMs\n",
        "\n",
        "Los grandes modelos de lenguaje (LLMs) son conocidos por su capacidad de aprender patrones complejos de los textos y de resolver en consecuencia varias tareas de procesamiento del lenguaje natural, como lo son la traducci√≥n autom√°tica, la generaci√≥n de res√∫menes y la resoluci√≥n de preguntas de dominios especializados. Es por esto que han surgido nuevas lineas de investigaci√≥n que buscan utilizar a los grandes modelos de lenguaje (LLMs) como *interpretadores sem√°nticos de textos*. Su objetivo es representar el significado de un texto escrito en lenguaje natural en uno o m√°s lenguajes l√≥gicos ‚Äîpor ejemplo, la l√≥gica proposicional o la l√≥gica de primer orden‚Äî para explicitar la informaci√≥n contenida all√≠ y brindarle mayor estructura. De esta manera, podemos obtener representaciones avanzadas del significado de un texto que sean m√°s faciles de almacenar en una computadora y puedan ser manipuladas algor√≠tmicamente.\n",
        "\n",
        "Un lenguaje l√≥gico que podemos utilizar para representar la informaci√≥n contenida en un texto es el lenguaje de los *Grafos de Conocimiento (KGs)*, los cuales permiten codificar hechos y proposiciones del mundo mediante ternas $(f,r,o)$ donde $f$ denota un concepto fuente, $r$ una relaci√≥n sem√°ntica y $o$ un concepto objetivo. As√≠, la informaci√≥n contenida en el siguiente texto:\n",
        "\n",
        "* *\"El Covid-19 es una enfermedad infecciosa causada por el SARS-CoV-2. Produce s√≠ntomas que incluyen fiebre, tos y fatiga\"*,\n",
        "\n",
        "puede representarse como la siguiente colecci√≥n de ternas de conocimiento:\n",
        "\n",
        "* *(Covid-19, es una, Enfermedad Infecciosa)*\n",
        "* *(Covid-19, causada por, SARS-CoV-2)*.\n",
        "* *(Covid-19, tiene s√≠ntoma, Fiebre)*.\n",
        "* *(Covid-19, tiene s√≠ntoma, Tos)*.\n",
        "* *(Covid-19, tiene s√≠ntoma, Fatiga)*.\n",
        "\n",
        "Esta colecci√≥n de ternas puede representase como un grafo dirigido y etiquetado, como se muestra en la siguiente figura:\n",
        "\n",
        "![GrafoConocimiento](https://raw.githubusercontent.com/matizzat/InforSanLuis-2025-LLMs/5596c0c724cd8e63742866ad998479ecd6f685d2/imagenes/grafo_conocimiento_covid19.svg)\n",
        "\n",
        "Vemos que este tipo de representaci√≥n es m√°s rica que el texto puro porque explicita los conceptos y relaciones m√°s relevantes. De esta manera, la interpretaci√≥n y el an√°lisis de la informaci√≥n extra√≠da se vuelven m√°s accesibles tanto para un usuario como para una computadora, y adem√°s se facilita su almacenamiento en bases de datos. Finalmente, si pudi√©ramos procesar autom√°ticamente un gran conjunto de documentos de un dominio especializado ‚Äîcomo la biolog√≠a o la medicina‚Äî y transformarlos en grafos de conocimiento, podr√≠amos aplicar todo el aparato matem√°tico de la Teor√≠a de Grafos para analizar estos sistemas conceptuales y revelar informaci√≥n del dominio que est√° escondida en los textos.\n",
        "\n",
        "En esta notebook utilizaremo al modelo Gemini junto a c√≥digo Python para crear autom√°ticamente grafos de conocimiento a partir de textos. Este ejercicio nos ense√±ar√° a coordinar diferentes invocaciones al modelo y a escribir correctamente nuestros prompts para sacarle el m√°ximo provecho posible.\n",
        "\n",
        "## Proceso de Interpretaci√≥n\n",
        "\n",
        "Vamos a implementar un procedimiento de interpretaci√≥n textual inspirado en la metodolog√≠a propuesta por Joseph Novak para la construcci√≥n de mapas conceptuales [1]. Este procedimiento permite generar un KG a partir de un texto expositivo mediante una secuencia estructurada de 4 pasos:\n",
        "\n",
        "1. Solicitamos al modelo que analice el texto ``<texto>`` y genere una pregunta de enfoque ``<pregunta>``. Las ternas de conocimiento generadas en los\n",
        "pr√≥ximos pasos deberƒ±ÃÅan ayudar a responder esta pregunta.\n",
        "\n",
        "2. Solicitamos al modelo que analice ``<texto>`` y ``<pregunta>`` y que luego genere una lista de conceptos ``<conceptos>``. Los conceptos extraƒ±ÃÅdos deben\n",
        "estar explicitamente mencionados en el texto y tienen que ayudar a responder la pregunta de enfoque.\n",
        "\n",
        "3. Solictamos al modelo que analice ``<texto>``, ``<pregunta>`` y ``<conceptos>`` y que genere una lista de relaciones sem√°nticas ``<relaciones>``.\n",
        "\n",
        "4. Solicitamos al modelo que analice ``<texto>``, ``<pregunta>``, ``<conceptos>`` y ``<relaciones>`` en conjunto y que luego genere una lista de ternas de conocimiento ``<ternas>``.\n",
        "\n",
        "En cada paso realizamos un procesamiento de las etiquetas de conceptos y relaciones para convertir todos sus caracteres a min√∫sculas y eliminar espacios en blanco innecesarios.\n",
        "\n",
        "## C√≥digo\n",
        "\n",
        "**Advertencia:** Si la API de Gemini no est√° disponible en este momento pueden simular el proceso en ChatGPT o el chat de Gemini y reintentar ejecutar el c√≥digo m√°s tarde.\n",
        "\n",
        "Primero extraemos los recursos desde Github (textos y prompts):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "LmeMMHkv2uQD",
      "metadata": {
        "id": "LmeMMHkv2uQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a0ca97-5368-4ccd-a966-f4f4c033042d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'InforSanLuis-2025-LLMs' already exists and is not an empty directory.\n",
            "/content/InforSanLuis-2025-LLMs\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/matizzat/InforSanLuis-2025-LLMs\n",
        "%cd InforSanLuis-2025-LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kk7yXrdQ3zgq",
      "metadata": {
        "id": "kk7yXrdQ3zgq"
      },
      "source": [
        "Instalamos la librer√≠a Pyvis para visualizar grafos de conocimiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "tXXeuRa13yat",
      "metadata": {
        "id": "tXXeuRa13yat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ffb624-5a78-4938-fae2-c8ed34931d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvis in /usr/local/lib/python3.12/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.12/dist-packages (from pyvis) (3.1.6)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pyvis) (4.1.1)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.12/dist-packages (from pyvis) (3.6)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4755f0d8-ccc7-4279-adab-5151480271d2",
      "metadata": {
        "id": "4755f0d8-ccc7-4279-adab-5151480271d2"
      },
      "source": [
        "Importamos las librer√≠as necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6073d8d-11fd-425e-91c2-b3dd8527e614",
      "metadata": {
        "id": "f6073d8d-11fd-425e-91c2-b3dd8527e614"
      },
      "outputs": [],
      "source": [
        "from pyvis.network import Network\n",
        "from google.colab import userdata\n",
        "from pyvis import network as net\n",
        "from google.genai import types\n",
        "from google import genai\n",
        "from typing import List\n",
        "import networkx as nx\n",
        "import pprint\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a90d4b6e-40b7-4d0c-a3bc-8f8dbb53f908",
      "metadata": {
        "id": "a90d4b6e-40b7-4d0c-a3bc-8f8dbb53f908"
      },
      "source": [
        "Instanciamos un cliente para invocar al modelo Gemini. Para ejecutar esta celda deben obtener una clave del siguiente [enlace](https://ai.google.dev/gemini-api/docs/api-key). Tambi√©n tienen que configurar Google Colab para utilizar esta clave (Ver  [Tutorial](https://www.youtube.com/watch?v=snrvP_TZjvw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c716a5d4-73f8-42d0-af35-8601a8567c25",
      "metadata": {
        "id": "c716a5d4-73f8-42d0-af35-8601a8567c25"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "cliente_genai = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64e52af6-528d-4b50-b649-44bb40370108",
      "metadata": {
        "id": "64e52af6-528d-4b50-b649-44bb40370108"
      },
      "source": [
        "Definimos una funci√≥n auxiliar para abrir el contenido de un archivo y cargamos las instrucciones con las que invocaremos al modelo. En cada invocaci√≥n nosotros le proveemos al modelo una **instrucci√≥n de sistema** y una **instrucci√≥n de usuario**:\n",
        "\n",
        "* En la instrucci√≥n de sistema nosotros le especificamos al modelo cual es el rol que debe cumplir, le explicamos en t√©rminos generales la tarea a resolver y le brindamos ejemplos concretos de c√≥mo hay que resolverla y cual es el formato de salida esperado.\n",
        "\n",
        "* En la instrucci√≥n de usuario especificamos cual es el texto corriente que queremos analizar.\n",
        "\n",
        "La t√©cnica donde le damos ejemplos concretos al modelo de c√≥mo debe resolver una tarea se denomina **aprendizaje en contexto** y es muy importante aprenderla para embeber a los LLMs en procesos autom√°ticos y aplicarlos en dominios especializados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0408ed3-7a5c-4720-9e06-dafdeaf4486e",
      "metadata": {
        "id": "e0408ed3-7a5c-4720-9e06-dafdeaf4486e"
      },
      "outputs": [],
      "source": [
        "def abrir_contenido_archivo(nombre_archivo: str):\n",
        "    with open(nombre_archivo, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "crear_pregunta_sistema   = abrir_contenido_archivo('./instrucciones/crear_pregunta_sistema.txt')\n",
        "crear_conceptos_sistema  = abrir_contenido_archivo('./instrucciones/crear_conceptos_sistema.txt')\n",
        "crear_relaciones_sistema = abrir_contenido_archivo('./instrucciones/crear_relaciones_sistema.txt')\n",
        "crear_ternas_sistema     = abrir_contenido_archivo('./instrucciones/crear_ternas_sistema.txt')\n",
        "\n",
        "crear_pregunta_usuario   = abrir_contenido_archivo('./instrucciones/crear_pregunta_usuario.txt')\n",
        "crear_conceptos_usuario  = abrir_contenido_archivo('./instrucciones/crear_conceptos_usuario.txt')\n",
        "crear_relaciones_usuario = abrir_contenido_archivo('./instrucciones/crear_relaciones_usuario.txt')\n",
        "crear_ternas_usuario     = abrir_contenido_archivo('./instrucciones/crear_ternas_usuario.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4295621f-be7a-4908-8f25-4e912b9fdc38",
      "metadata": {
        "id": "4295621f-be7a-4908-8f25-4e912b9fdc38"
      },
      "source": [
        "Ejecuten la siguiente celda probando distintos valores para visualizar las instrucciones con las que vamos a invocar al modelo. Observar que las instrucciones del usuario funcionan como plantillas: las completamos din√°micamente a medida que el LLM avance en cada paso del proceso. Los espacios a modificar din√°micamente est√°n encerrados entre llaves ``{`` y ``}``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4640de7e-427b-4029-aac2-86232909e5d4",
      "metadata": {
        "id": "4640de7e-427b-4029-aac2-86232909e5d4"
      },
      "outputs": [],
      "source": [
        "print(crear_conceptos_sistema)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53822b55-b553-44a3-9e89-d8741779e6e4",
      "metadata": {
        "id": "53822b55-b553-44a3-9e89-d8741779e6e4"
      },
      "source": [
        "A continuaci√≥n definimos funciones auxiliares que necesitaremos en nuestro proceso:\n",
        "* ``invocar_llm`` recibe como par√°metros una instrucci√≥n de sistema y una instrucci√≥n de usuario y con ellos invoca al modelo Gemini 2.5 Flash. La invocaci√≥n esta fijada con un valor de temperatura bajo para que las respuestas del modelo sean determin√≠sticas y no var√≠en en diferentes invocaciones.  \n",
        "* ``abrir_lote_de_documentos`` se encarga de abrir una lista de documentos desde la ruta especificada. Cada documento posee un t√≠tulo y un texto.\n",
        "* ``guardar_mapa_conceptuales``: Almacena una lista de mapas conceptuales en un archivo JSON. Cada mapa conceptual est√° codificado como un diccionario que tiene los siguientes elementos:\n",
        "  * ``titulo``: Un string con el t√≠tulo del mapa conceptual para identificarlo.\n",
        "  * ``pregunta``: Un string que representa la pregunta focal.\n",
        "  * ``conceptos``: Una lista de strings que representa las etiquetas de conceptos.\n",
        "  * ``relaciones``: Una lista de strings que representa las etiquetas de las relaciones sem√°nticas.\n",
        "  * ``ternas``. Una lista de ternas de conocimiento, donde cada una es un diccionario con las componentes `f` (concepto fuente), `r` (relaci√≥n) y `o` (concepto objetivo).\n",
        "* ``dibujar_mapas_conceptuales``: Dibuja un conjunto de mapas conceptuales como un √∫nico grafo dirigido y etiquetado, el cual se almacena en un archivo HTML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd7a86f-a1e8-4e22-821d-0432fa9986e4",
      "metadata": {
        "id": "6dd7a86f-a1e8-4e22-821d-0432fa9986e4"
      },
      "outputs": [],
      "source": [
        "def invocar_llm(sistema: str, usuario: str):\n",
        "    \"\"\"\n",
        "    Invoca al modelo de lenguaje Gemini 2.5 Flash.\n",
        "\n",
        "    Par√°metros:\n",
        "        sistema (str): Instrucciones del sistema para el modelo.\n",
        "        usuario  (str): Consulta o instrucciones del usuario.\n",
        "\n",
        "    Retorna:\n",
        "        str: Texto generado por el modelo.\n",
        "    \"\"\"\n",
        "    global cliente_genai\n",
        "\n",
        "    respuesta = cliente_genai.models.generate_content(\n",
        "        config = types.GenerateContentConfig(\n",
        "            system_instruction = sistema,\n",
        "            temperature = 0.1\n",
        "        ),\n",
        "        model = \"gemini-2.5-flash\",\n",
        "        contents = usuario\n",
        "    )\n",
        "\n",
        "    return respuesta.text\n",
        "\n",
        "\n",
        "def abrir_lote_de_documentos(ruta_entrada: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Abre un lote de documentos desde un archivo JSON.\n",
        "\n",
        "    Par√°metros:\n",
        "        ruta_entrada (str): Ruta del archivo que contiene los documentos.\n",
        "\n",
        "    Retorna:\n",
        "        list[dict]: Lista de documentos.\n",
        "    \"\"\"\n",
        "    with open(ruta_entrada, 'r') as f:\n",
        "        textos = json.load(f)\n",
        "    return textos\n",
        "\n",
        "\n",
        "def guardar_mapas_conceptuales(ruta_salida: str, mapas: dict):\n",
        "    \"\"\"\n",
        "    Guarda una lista de mapas conceptuales en un archivo JSON.\n",
        "\n",
        "    Par√°metros:\n",
        "        ruta_salida (str): Ruta del archivo de salida.\n",
        "        mapas (dict): Mapas conceptuales a guardar.\n",
        "    \"\"\"\n",
        "    with open(ruta_salida, 'w') as f:\n",
        "        json.dump(mapas, f, indent=4)\n",
        "\n",
        "\n",
        "def dibujar_mapas_conceptuales(ruta_salida: str, mapas: dict):\n",
        "    \"\"\"\n",
        "    Crea una visualizaci√≥n pyvis de una lista de mapas conceptuales\n",
        "    y la guarda como archivo HTML.\n",
        "\n",
        "    Par√°metros:\n",
        "        mapas (dict): Lista de mapas conceptuales.\n",
        "        ruta_salida (str): Archivo HTML donde se guardar√° la visualizaci√≥n.\n",
        "    \"\"\"\n",
        "    G = nx.MultiDiGraph()\n",
        "\n",
        "    for mapa in mapas:\n",
        "        pregunta_focal = mapa['pregunta']\n",
        "        ternas = mapa['ternas']\n",
        "\n",
        "        for terna in ternas:\n",
        "            f = terna['f']\n",
        "            r = terna['r']\n",
        "            o = terna['o']\n",
        "\n",
        "            if f not in G:\n",
        "                G.add_node(f, label=f, color='black')\n",
        "            if o not in G:\n",
        "                G.add_node(o, label=o, color='black')\n",
        "\n",
        "            G.add_edge(\n",
        "                f,\n",
        "                o,\n",
        "                label=r,\n",
        "                title=pregunta_focal,\n",
        "                color='blue'\n",
        "            )\n",
        "\n",
        "    vis = net.Network(directed=True)\n",
        "    vis.from_nx(G)\n",
        "    vis.save_graph(ruta_salida)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5af50622-266b-42f3-a637-5f09c26b1439",
      "metadata": {
        "id": "5af50622-266b-42f3-a637-5f09c26b1439"
      },
      "source": [
        "Abrimos el lote de documentos y mostramos el texto del primer documento que est√° almacenado all√≠. Si revisan el archivo `documentos.json` ver√°n que cada documento consiste de un t√≠tulo y un texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb84fa0-93c9-435e-9d41-f02ff50d818e",
      "metadata": {
        "id": "ffb84fa0-93c9-435e-9d41-f02ff50d818e"
      },
      "outputs": [],
      "source": [
        "documentos = abrir_lote_de_documentos('./datos/documentos.json')\n",
        "texto = documentos[0]['texto']\n",
        "print(texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1f7e9ec-ae61-4d64-8411-0cde4d808661",
      "metadata": {
        "id": "c1f7e9ec-ae61-4d64-8411-0cde4d808661"
      },
      "source": [
        "Definimos una funci√≥n auxiliar para normalizar la etiqueta de un concepto o una relaci√≥n sem√°ntica. Esta elimina el car√°cter especial `@`, quita los espacios en blanco innecesarios y convierte todas las letras a min√∫sculas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb66aa6c-a86c-4245-9f43-1e6268cf16f0",
      "metadata": {
        "id": "eb66aa6c-a86c-4245-9f43-1e6268cf16f0"
      },
      "outputs": [],
      "source": [
        "def normalizar_etiqueta(etiqueta: str):\n",
        "    etiqueta = etiqueta.replace('@','')\n",
        "    etiqueta = etiqueta.strip()\n",
        "    etiqueta = \" \".join(etiqueta.split())\n",
        "    etiqueta = etiqueta.lower()\n",
        "    return etiqueta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c06d986-71a9-4667-ab5e-22b1333dd0a2",
      "metadata": {
        "id": "2c06d986-71a9-4667-ab5e-22b1333dd0a2"
      },
      "source": [
        "Formateamos el prompt de usuario para instruirle al modelo que genere una pregunta de enfoque."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e53397-4b7e-4509-b6bc-f273b994f058",
      "metadata": {
        "id": "d8e53397-4b7e-4509-b6bc-f273b994f058"
      },
      "outputs": [],
      "source": [
        "instruccion_crear_pregunta_formateada = crear_pregunta_usuario.format(texto = texto)\n",
        "print(instruccion_crear_pregunta_formateada )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d999a742-5ba9-45cf-a269-a94adbe0cb42",
      "metadata": {
        "id": "d999a742-5ba9-45cf-a269-a94adbe0cb42"
      },
      "source": [
        "Invocamos al modelo de lenguaje y le solicitamos que cree una pregunta focal para el texto dado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aafadf89-37f1-4d4d-986b-82e8adaae6e5",
      "metadata": {
        "id": "aafadf89-37f1-4d4d-986b-82e8adaae6e5"
      },
      "outputs": [],
      "source": [
        "pregunta_focal = invocar_llm(\n",
        "    usuario = instruccion_crear_pregunta_formateada,\n",
        "    sistema = crear_pregunta_sistema)\n",
        "\n",
        "pregunta_focal = normalizar_etiqueta(pregunta_focal)\n",
        "print(pregunta_focal)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cdb9a9-b159-497a-baf2-d70c8eac5f46",
      "metadata": {
        "id": "38cdb9a9-b159-497a-baf2-d70c8eac5f46"
      },
      "source": [
        "Formateamos el prompt de usuario para instruirle al modelo que genere una lista de conceptos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffcbe666-6031-4b6f-a788-d694ba3637e6",
      "metadata": {
        "id": "ffcbe666-6031-4b6f-a788-d694ba3637e6"
      },
      "outputs": [],
      "source": [
        "instruccion_crear_conceptos_formateada = crear_conceptos_usuario.format(pregunta = pregunta_focal, texto = texto)\n",
        "print(instruccion_crear_conceptos_formateada)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b93d48-c7d8-47e2-8f12-ae9932b7e7db",
      "metadata": {
        "id": "95b93d48-c7d8-47e2-8f12-ae9932b7e7db"
      },
      "source": [
        "Invocamos al modelo de lenguaje para que genere una lista de conceptos a partir del texto y la pregunta de enfoque:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d73235e-7c57-47f7-aa16-0c53b7c82d73",
      "metadata": {
        "id": "4d73235e-7c57-47f7-aa16-0c53b7c82d73"
      },
      "outputs": [],
      "source": [
        "respuesta_llm = invocar_llm(\n",
        "    usuario = instruccion_crear_conceptos_formateada,\n",
        "    sistema = crear_conceptos_sistema)\n",
        "\n",
        "print(respuesta_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f4534bc-1342-4a35-8197-0bddcd154177",
      "metadata": {
        "id": "5f4534bc-1342-4a35-8197-0bddcd154177"
      },
      "source": [
        "Convertimos el texto extraido en una lista de Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be0b026b-90b6-4837-906c-f20a3c559e4e",
      "metadata": {
        "id": "be0b026b-90b6-4837-906c-f20a3c559e4e"
      },
      "outputs": [],
      "source": [
        "# Expresi√≥n regular para extraer una lista de conceptos:\n",
        "conceptos_exp_reg = r'[\\w\\d].*?\\n|[\\w\\d].*$'\n",
        "\n",
        "lista_conceptos = re.findall(conceptos_exp_reg, respuesta_llm)\n",
        "lista_conceptos = [normalizar_etiqueta(concepto) for concepto in lista_conceptos]\n",
        "\n",
        "pprint.pprint(lista_conceptos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c49c6c-c5e8-41ce-9eb7-aacd1059ebac",
      "metadata": {
        "id": "78c49c6c-c5e8-41ce-9eb7-aacd1059ebac"
      },
      "source": [
        "Formateamos el prompt de usuario para instruirle al modelo que genere una lista de relaciones sem√°nticas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "525960c5-7c2b-42dd-8b8a-ef14dec891d0",
      "metadata": {
        "id": "525960c5-7c2b-42dd-8b8a-ef14dec891d0"
      },
      "outputs": [],
      "source": [
        "instruccion_crear_relaciones_formateada = crear_relaciones_usuario.format(\n",
        "    pregunta = pregunta_focal,\n",
        "    conceptos = \"\\n\".join(lista_conceptos),\n",
        "    texto = texto)\n",
        "print(instruccion_crear_relaciones_formateada)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3370fd19-8787-4d5c-b94e-35d7ac313bcb",
      "metadata": {
        "id": "3370fd19-8787-4d5c-b94e-35d7ac313bcb"
      },
      "source": [
        "Invocamos al modelo de lenguaje para que genere una lista de relaciones a partir del texto, la pregunta de enfoque y la lista de conceptos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9937f722-0310-4ba5-b898-12920c95d11b",
      "metadata": {
        "id": "9937f722-0310-4ba5-b898-12920c95d11b"
      },
      "outputs": [],
      "source": [
        "respuesta_llm = invocar_llm(\n",
        "    sistema = crear_relaciones_sistema,\n",
        "    usuario = instruccion_crear_relaciones_formateada)\n",
        "\n",
        "print(respuesta_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uBEYl2YV5tde",
      "metadata": {
        "id": "uBEYl2YV5tde"
      },
      "source": [
        "Convertimos el texto extraido en una lista de Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c21bef-580e-4cc2-94ab-18fa2897b085",
      "metadata": {
        "id": "64c21bef-580e-4cc2-94ab-18fa2897b085"
      },
      "outputs": [],
      "source": [
        "# Expresi√≥n regular para extraer una lista de relaciones sem√°nticas:\n",
        "relaciones_exp_reg = r'[\\w\\d].*?\\n|[\\w\\d].*$'\n",
        "\n",
        "lista_relaciones = re.findall(relaciones_exp_reg, respuesta_llm)\n",
        "lista_relaciones = [normalizar_etiqueta(relacion) for relacion in lista_relaciones]\n",
        "\n",
        "pprint.pprint(lista_relaciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8761cc0-0b49-4b35-8308-6b253094ad69",
      "metadata": {
        "id": "c8761cc0-0b49-4b35-8308-6b253094ad69"
      },
      "source": [
        "Formateamos el prompt de usuario para instruirle al modelo que genere una lista de ternas de conocimiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a240fb4d-6ab0-4b5c-b867-0a16c671547f",
      "metadata": {
        "id": "a240fb4d-6ab0-4b5c-b867-0a16c671547f"
      },
      "outputs": [],
      "source": [
        "instruccion_crear_ternas_formateada = crear_ternas_usuario.format(\n",
        "    pregunta = pregunta_focal,\n",
        "    conceptos = \"\\n\".join(lista_conceptos),\n",
        "    relaciones = \"\\n\".join(lista_relaciones),\n",
        "    texto = texto)\n",
        "\n",
        "print(instruccion_crear_ternas_formateada)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114fd099-208c-4533-a188-bdf5a41aac03",
      "metadata": {
        "id": "114fd099-208c-4533-a188-bdf5a41aac03"
      },
      "source": [
        "Invocamos al modelo de lenguaje para que genere una lista de ternas de conocimiento  a partir del texto, la pregunta de enfoque, la lista de conceptos y la lista de relaciones sem√°nticas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5ebb34-1ffe-4224-b626-c824eb562c89",
      "metadata": {
        "id": "8d5ebb34-1ffe-4224-b626-c824eb562c89"
      },
      "outputs": [],
      "source": [
        "respuesta_llm = invocar_llm(\n",
        "    sistema = crear_ternas_sistema,\n",
        "    usuario = instruccion_crear_ternas_formateada)\n",
        "\n",
        "print(respuesta_llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cfd3bf2-ae98-4601-9b33-fb478e07ede4",
      "metadata": {
        "id": "3cfd3bf2-ae98-4601-9b33-fb478e07ede4"
      },
      "source": [
        "Extraemos las ternas de conocimiento del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798228ad-f021-450f-b1a3-da6a23fc11b3",
      "metadata": {
        "id": "798228ad-f021-450f-b1a3-da6a23fc11b3"
      },
      "outputs": [],
      "source": [
        "ternas_exp_reg = r'@! (.+?) @ (.+?) @ (.+?) !@'\n",
        "\n",
        "L = re.findall(ternas_exp_reg, respuesta_llm)\n",
        "\n",
        "lista_ternas = []\n",
        "\n",
        "for f, r, o in L:\n",
        "    lista_ternas.append({\n",
        "        'f': normalizar_etiqueta(f),\n",
        "        'r': normalizar_etiqueta(r),\n",
        "        'o': normalizar_etiqueta(o)\n",
        "    })\n",
        "\n",
        "pprint.pprint(lista_ternas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95783938-b343-4cb0-a849-ee6b450502c7",
      "metadata": {
        "id": "95783938-b343-4cb0-a849-ee6b450502c7"
      },
      "source": [
        "Unimos todas las componentes obtenidas en un √∫nico diccionario Python que representa el grafo de conocimiento (o mapa conceptual):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e89173b-b05b-488e-833c-7f3edd180218",
      "metadata": {
        "id": "6e89173b-b05b-488e-833c-7f3edd180218"
      },
      "outputs": [],
      "source": [
        "mapa_conceptual = {'titulo': documentos[0]['titulo'], 'pregunta': pregunta_focal, 'ternas': lista_ternas, 'conceptos': lista_conceptos, 'relaciones': lista_relaciones}\n",
        "pprint.pprint(mapa_conceptual)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ae1e729-5cc2-4a97-a433-cc4e77bf8fbc",
      "metadata": {
        "id": "5ae1e729-5cc2-4a97-a433-cc4e77bf8fbc"
      },
      "source": [
        "Almacenamos en un archivo JSON el grafo de conocimiento obtenido y lo visalizamos en un archivo HTML üòÄ. Para ver el grafo descarguen el archivo `mapas.html` y abranlo en una nueva pesta√±a de su navegador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ef88889-d3ec-41ad-a62e-fa24652710ae",
      "metadata": {
        "id": "7ef88889-d3ec-41ad-a62e-fa24652710ae"
      },
      "outputs": [],
      "source": [
        "guardar_mapas_conceptuales('./mapas.json', [mapa_conceptual])\n",
        "dibujar_mapas_conceptuales('./mapas.html', [mapa_conceptual])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c68e22cd-ea1c-4403-bdee-6e0d49c64246",
      "metadata": {
        "id": "c68e22cd-ea1c-4403-bdee-6e0d49c64246"
      },
      "source": [
        "# Tarea\n",
        "\n",
        "La tarea consiste en dise√±ar e implementar una estrategia propia para la creaci√≥n de mapas conceptuales utilizando el modelo de lenguaje Gemini. Todo el proceso debe integrarse en una funci√≥n llamada crear_mapa_conceptual, la cual recibe como entrada un texto y devuelve como salida un diccionario de Python que codifica el mapa conceptual correspondiente.\n",
        "\n",
        "A partir del archivo `documentos.json`, deber√°n generar un √∫nico mapa conceptual por cada texto, y almacenar todos ellos en un √∫nico archivo JSON `mapas.json`, siguiendo el formato ilustrado en el ejemplo anterior.\n",
        "\n",
        "Se recomienda experimentar con distintas estrategias de prompting y diferentes algoritmos. Pueden usar como referencia los prompts y piezas de c√≥digo presentados en la secci√≥n previa. Adem√°s, el siguiente recurso puede serles √∫til como gu√≠a para dise√±ar prompts:\n",
        "https://www.promptingguide.ai/\n",
        "\n",
        "**Consejo**:\n",
        "* Incorporen un paso adicional en la estrategia anterior que le pida al LLM mejorar un mapa conceptual previamente generado.\n",
        "\n",
        "---\n",
        "\n",
        "### Entrega\n",
        "\n",
        "Cuando finalicen, suban su notebook, los prompts utilizados y todos los archivos con los mapas conceptuales generados a un repositorio p√∫blico de GitHub. Env√≠en el enlace del repositorio al correo mat.torreta@gmail.com con el asunto:\n",
        "\n",
        "* *InforSanLuis25-LLMs Entrega*\n",
        "\n",
        "En el cuerpo del correo deben incluir:\n",
        "\n",
        "* Nombre completo\n",
        "\n",
        "* DNI\n",
        "\n",
        "La entrega deber√° realizarse antes del viernes 05 de diciembre a las 23:59 para aprobar el curso.\n",
        "\n",
        "---\n",
        "\n",
        "### M√©todo a implementar\n",
        "\n",
        "Implementen la mayor parte de su estrategia de creaci√≥n de mapas conceptuales en el cuerpo de esta funci√≥n. Pueden crear sus propias funciones auxiliares e invocarlas desde aqu√≠ si lo necesitan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6d4cbb5a-f1e1-4472-a5df-20bf14e83112",
      "metadata": {
        "id": "6d4cbb5a-f1e1-4472-a5df-20bf14e83112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32d00433-4147-4269-a606-3ceca6076ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando procesamiento de 5 documentos (Refinamiento: 2 iteraciones)...\n",
            "\n",
            "--- Procesando 1/5: agua ---\n",
            "‚úÖ Mapa finalizado y refinado. Ternas finales: 15\n",
            "Esperando 20 segundos...\n",
            "\n",
            "--- Procesando 2/5: don_quijote ---\n",
            "‚úÖ Mapa finalizado y refinado. Ternas finales: 10\n",
            "Esperando 20 segundos...\n",
            "\n",
            "--- Procesando 3/5: proteina_a ---\n",
            "‚úÖ Mapa finalizado y refinado. Ternas finales: 20\n",
            "Esperando 20 segundos...\n",
            "\n",
            "--- Procesando 4/5: anticuerpo ---\n",
            "‚úÖ Mapa finalizado y refinado. Ternas finales: 14\n",
            "Esperando 20 segundos...\n",
            "\n",
            "--- Procesando 5/5: ojo ---\n",
            "‚úÖ Mapa finalizado y refinado. Ternas finales: 21\n",
            "\n",
            "‚ú® ¬°Proceso completado! Archivos './mapas.json' y './mapas.html' generados.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import time\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Librer√≠as esenciales (Asume que ya ejecutaste !pip install pyvis)\n",
        "from pyvis.network import Network\n",
        "from google.colab import userdata\n",
        "from pyvis import network as net\n",
        "from google.genai import types\n",
        "from google import genai\n",
        "import networkx as nx\n",
        "import pprint\n",
        "\n",
        "## üõ†Ô∏è CONFIGURACI√ìN E INICIALIZACI√ìN\n",
        "# ==============================================================================\n",
        "\n",
        "# 1. Inicializar el cliente Gemini\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    cliente_genai = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: No se pudo inicializar el cliente Gemini. Detalle: {e}\")\n",
        "    cliente_genai = None\n",
        "\n",
        "# 2. Expresiones Regulares Globales\n",
        "ternas_exp_reg = r'@! (.+?) @ (.+?) @ (.+?) !@'\n",
        "conceptos_exp_reg = r'[\\w\\d].*?\\n|[\\w\\d].*$'\n",
        "relaciones_exp_reg = r'[\\w\\d].*?\\n|[\\w\\d].*$'\n",
        "\n",
        "# 3. Funciones Auxiliares\n",
        "def invocar_llm(sistema: str, usuario: str) -> str:\n",
        "    \"\"\"Invoca al modelo de lenguaje Gemini 2.5 Flash.\"\"\"\n",
        "    global cliente_genai\n",
        "    if not cliente_genai:\n",
        "        return \"\"\n",
        "    try:\n",
        "        respuesta = cliente_genai.models.generate_content(\n",
        "            config = types.GenerateContentConfig(\n",
        "                system_instruction = sistema,\n",
        "                temperature = 0.1\n",
        "            ),\n",
        "            model = \"gemini-2.5-flash\",\n",
        "            contents = usuario\n",
        "        )\n",
        "        return respuesta.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error LLM: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def normalizar_etiqueta(etiqueta: str) -> str:\n",
        "    \"\"\"Limpia y normaliza etiquetas de conceptos/relaciones.\"\"\"\n",
        "    etiqueta = etiqueta.replace('@','')\n",
        "    etiqueta = etiqueta.strip()\n",
        "    etiqueta = \" \".join(etiqueta.split())\n",
        "    etiqueta = etiqueta.lower()\n",
        "    return etiqueta\n",
        "\n",
        "def abrir_contenido_archivo(nombre_archivo: str) -> str:\n",
        "    \"\"\"Lee el contenido de un archivo (usado para cargar prompts).\"\"\"\n",
        "    try:\n",
        "        with open(nombre_archivo, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ADVERTENCIA: Archivo de prompt no encontrado: {nombre_archivo}\")\n",
        "        return \"\"\n",
        "\n",
        "def abrir_lote_de_documentos(ruta_entrada: str) -> list[dict]:\n",
        "    \"\"\"Abre un lote de documentos desde un archivo JSON.\"\"\"\n",
        "    try:\n",
        "        with open(ruta_entrada, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar documentos: {e}\")\n",
        "        return []\n",
        "\n",
        "def guardar_mapas_conceptuales(ruta_salida: str, mapas: list[dict]):\n",
        "    \"\"\"Guarda una lista de mapas conceptuales en un archivo JSON.\"\"\"\n",
        "    with open(ruta_salida, 'w', encoding='utf-8') as f:\n",
        "        json.dump(mapas, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def dibujar_mapas_conceptuales(ruta_salida: str, mapas: list[dict]):\n",
        "    \"\"\"Crea una visualizaci√≥n pyvis de una lista de mapas conceptuales.\"\"\"\n",
        "    G = nx.MultiDiGraph()\n",
        "    for mapa in mapas:\n",
        "        pregunta_focal = mapa['pregunta']\n",
        "        ternas = mapa['ternas']\n",
        "        for terna in ternas:\n",
        "            f = terna['f']\n",
        "            r = terna['r']\n",
        "            o = terna['o']\n",
        "            if f not in G: G.add_node(f, label=f, color='black')\n",
        "            if o not in G: G.add_node(o, label=o, color='black')\n",
        "            G.add_edge(f, o, label=r, title=pregunta_focal, color='blue')\n",
        "    vis = net.Network(directed=True)\n",
        "    vis.from_nx(G)\n",
        "    vis.save_graph(ruta_salida)\n",
        "\n",
        "\n",
        "## üìù CARGA DE PROMPTS Y DEFINICI√ìN DE REFINAMIENTO\n",
        "# ==============================================================================\n",
        "# Carga de Prompts (Asumiendo que est√°n en './instrucciones/')\n",
        "crear_pregunta_sistema   = abrir_contenido_archivo('./instrucciones/crear_pregunta_sistema.txt')\n",
        "crear_conceptos_sistema  = abrir_contenido_archivo('./instrucciones/crear_conceptos_sistema.txt')\n",
        "crear_relaciones_sistema = abrir_contenido_archivo('./instrucciones/crear_relaciones_sistema.txt')\n",
        "crear_ternas_sistema     = abrir_contenido_archivo('./instrucciones/crear_ternas_sistema.txt')\n",
        "\n",
        "crear_pregunta_usuario   = abrir_contenido_archivo('./instrucciones/crear_pregunta_usuario.txt')\n",
        "crear_conceptos_usuario  = abrir_contenido_archivo('./instrucciones/crear_conceptos_usuario.txt')\n",
        "crear_relaciones_usuario = abrir_contenido_archivo('./instrucciones/crear_relaciones_usuario.txt')\n",
        "crear_ternas_usuario     = abrir_contenido_archivo('./instrucciones/crear_ternas_usuario.txt')\n",
        "\n",
        "# Prompts para el Paso 5: Refinamiento\n",
        "refinar_ternas_sistema = \"\"\"\n",
        "Eres un experto en extracci√≥n de informaci√≥n y refinamiento de grafos de conocimiento. Tu tarea es analizar un texto, una pregunta focal, una lista de conceptos y una colecci√≥n de ternas de conocimiento existentes. Debes refinar estas ternas para mejorar su precisi√≥n, completar informaci√≥n faltante o establecer nuevas conexiones l√≥gicas, asegur√°ndote de que todas las ternas sean consistentes con el texto original y la pregunta focal.\n",
        "\n",
        "El formato de salida deseado es una lista de ternas de conocimiento revisadas, cada una en el formato `@! concepto_fuente @ relacion @ concepto_objetivo !@`. Solo debes devolver las ternas revisadas, una por l√≠nea, sin texto adicional.\n",
        "\"\"\"\n",
        "refinar_ternas_usuario = \"\"\"\n",
        "Texto de Conocimiento:\n",
        "@\n",
        "{texto}\n",
        "@\n",
        "Pregunta Focal:\n",
        "{pregunta}\n",
        "Lista de Conceptos:\n",
        "{conceptos}\n",
        "Lista de Relaciones:\n",
        "{relaciones}\n",
        "Ternas de Conocimiento Originales:\n",
        "{ternas_originales}\n",
        "@\n",
        "Tripletas de Conocimiento Revisadas:\n",
        "\"\"\"\n",
        "\n",
        "## üöÄ FUNCIONES PRINCIPALES\n",
        "# ==============================================================================\n",
        "\n",
        "def crear_mapa_conceptual(texto: str) -> dict:\n",
        "    \"\"\"Genera la estructura inicial de un mapa conceptual (Pasos 1 a 4).\"\"\"\n",
        "    global conceptos_exp_reg, relaciones_exp_reg, ternas_exp_reg\n",
        "\n",
        "    # 1. Pregunta Focal\n",
        "    pregunta_focal = normalizar_etiqueta(invocar_llm(\n",
        "        usuario=crear_pregunta_usuario.format(texto=texto), sistema=crear_pregunta_sistema))\n",
        "\n",
        "    # 2. Lista de Conceptos\n",
        "    respuesta_conceptos = invocar_llm(\n",
        "        usuario=crear_conceptos_usuario.format(pregunta=pregunta_focal, texto=texto), sistema=crear_conceptos_sistema)\n",
        "    lista_conceptos = [normalizar_etiqueta(c) for c in re.findall(conceptos_exp_reg, respuesta_conceptos) if c.strip()]\n",
        "\n",
        "    # 3. Lista de Relaciones\n",
        "    respuesta_relaciones = invocar_llm(\n",
        "        sistema=crear_relaciones_sistema,\n",
        "        usuario=crear_relaciones_usuario.format(pregunta=pregunta_focal, conceptos=\"\\n\".join(lista_conceptos), texto=texto))\n",
        "    lista_relaciones = [normalizar_etiqueta(r) for r in re.findall(relaciones_exp_reg, respuesta_relaciones) if r.strip()]\n",
        "    if lista_relaciones and lista_relaciones[0] == 'relaciones sem√°nticas:': lista_relaciones.pop(0)\n",
        "\n",
        "    # 4. Ternas de Conocimiento Iniciales\n",
        "    respuesta_ternas = invocar_llm(\n",
        "        sistema=crear_ternas_sistema,\n",
        "        usuario=crear_ternas_usuario.format(pregunta=pregunta_focal, conceptos=\"\\n\".join(lista_conceptos), relaciones=\"\\n\".join(lista_relaciones), texto=texto))\n",
        "\n",
        "    L = re.findall(ternas_exp_reg, respuesta_ternas)\n",
        "    lista_ternas = [{'f': normalizar_etiqueta(f), 'r': normalizar_etiqueta(r), 'o': normalizar_etiqueta(o)} for f, r, o in L]\n",
        "\n",
        "    return {\n",
        "        'pregunta': pregunta_focal,\n",
        "        'ternas': lista_ternas,\n",
        "        'conceptos': lista_conceptos,\n",
        "        'relaciones': lista_relaciones\n",
        "    }\n",
        "\n",
        "def refinar_mapa_conceptual(mapa: dict, texto_original: str, num_iteraciones: int = 1) -> dict:\n",
        "    \"\"\"Implementa el Paso 5: Refina las ternas de un mapa conceptual de forma iterativa.\"\"\"\n",
        "    global refinar_ternas_usuario, refinar_ternas_sistema\n",
        "    ternas_actuales = mapa['ternas']\n",
        "\n",
        "    for i in range(num_iteraciones):\n",
        "        # Prepara el string de ternas para el prompt\n",
        "        ternas_originales_str = \"\\n\".join([f\"@! {t['f']} @ {t['r']} @ {t['o']} !@\" for t in ternas_actuales])\n",
        "\n",
        "        # Formatea el prompt de usuario\n",
        "        instruccion_refinar_ternas = refinar_ternas_usuario.format(\n",
        "            texto=texto_original,\n",
        "            pregunta=mapa['pregunta'],\n",
        "            conceptos=\"\\n\".join(mapa['conceptos']),\n",
        "            relaciones=\"\\n\".join(mapa['relaciones']),\n",
        "            ternas_originales=ternas_originales_str)\n",
        "\n",
        "        # Invoca al LLM para refinamiento\n",
        "        respuesta_llm_refinada = invocar_llm(\n",
        "            sistema=refinar_ternas_sistema, usuario=instruccion_refinar_ternas)\n",
        "\n",
        "        # Parsear y actualizar las ternas para la siguiente iteraci√≥n\n",
        "        refined_L = re.findall(ternas_exp_reg, respuesta_llm_refinada)\n",
        "        ternas_actuales = [{'f': normalizar_etiqueta(f), 'r': normalizar_etiqueta(r), 'o': normalizar_etiqueta(o)} for f, r, o in refined_L]\n",
        "\n",
        "    mapa['ternas'] = ternas_actuales\n",
        "    return mapa\n",
        "\n",
        "## ‚öôÔ∏è ORQUESTACI√ìN Y EJECUCI√ìN\n",
        "# ==============================================================================\n",
        "\n",
        "def procesar_lote_de_documentos(ruta_entrada: str = './datos/documentos.json', ruta_salida_json: str = './mapas.json', ruta_salida_html: str = './mapas.html', iteraciones_refinamiento: int = 2, delay_seg: int = 20):\n",
        "    \"\"\"Orquesta la generaci√≥n y refinamiento de mapas para todos los documentos.\"\"\"\n",
        "\n",
        "    documentos = abrir_lote_de_documentos(ruta_entrada)\n",
        "    if not documentos: return\n",
        "\n",
        "    mapas_conceptuales_finales = []\n",
        "    num_documentos = len(documentos)\n",
        "\n",
        "    print(f\"Iniciando procesamiento de {num_documentos} documentos (Refinamiento: {iteraciones_refinamiento} iteraciones)...\")\n",
        "\n",
        "    for i, doc in enumerate(documentos):\n",
        "        titulo = doc.get('titulo', f\"Documento {i+1}\")\n",
        "        texto = doc.get('texto', '')\n",
        "\n",
        "        if not texto.strip():\n",
        "            print(f\"--- Saltando Documento {i+1}: '{titulo}' (Texto vac√≠o) ---\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n--- Procesando {i+1}/{num_documentos}: {titulo} ---\")\n",
        "\n",
        "        try:\n",
        "            # 1. Generaci√≥n Inicial (Pasos 1-4)\n",
        "            mapa_generado = crear_mapa_conceptual(texto)\n",
        "            mapa_generado['titulo'] = titulo\n",
        "\n",
        "            # 2. Refinamiento (Paso 5)\n",
        "            mapa_final = refinar_mapa_conceptual(mapa_generado, texto, num_iteraciones=iteraciones_refinamiento)\n",
        "\n",
        "            mapas_conceptuales_finales.append(mapa_final)\n",
        "            print(f\"‚úÖ Mapa finalizado y refinado. Ternas finales: {len(mapa_final['ternas'])}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error al procesar '{titulo}': {e}\")\n",
        "\n",
        "        # Pausa para evitar exceder los l√≠mites de la API\n",
        "        if i < num_documentos - 1 and delay_seg > 0:\n",
        "            print(f\"Esperando {delay_seg} segundos...\")\n",
        "            time.sleep(delay_seg)\n",
        "\n",
        "    # 3. Guardar y Dibujar el resultado\n",
        "    guardar_mapas_conceptuales(ruta_salida_json, mapas_conceptuales_finales)\n",
        "    dibujar_mapas_conceptuales(ruta_salida_html, mapas_conceptuales_finales)\n",
        "\n",
        "    print(f\"\\n‚ú® ¬°Proceso completado! Archivos '{ruta_salida_json}' y '{ruta_salida_html}' generados.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Ejecuci√≥n del Proceso ---\n",
        "    # Asume que el directorio ya est√° configurado con !git clone y %cd\n",
        "    procesar_lote_de_documentos(\n",
        "        ruta_entrada='./datos/documentos.json',\n",
        "        ruta_salida_json='./mapas.json',\n",
        "        ruta_salida_html='./mapas.html',\n",
        "        iteraciones_refinamiento=2,\n",
        "        delay_seg=20\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e50cdc6-f625-43c0-b080-913a6ba93479",
      "metadata": {
        "id": "7e50cdc6-f625-43c0-b080-913a6ba93479"
      },
      "source": [
        "# Bibliograf√≠a\n",
        "\n",
        "* [Unifying Large Language Models and Knowledge Graphs: A Roadmap](https://arxiv.org/abs/2306.08302) de Shirui Pan, et al.\n",
        "* [The Theory Underlying Concept Maps and How\n",
        "to Construct and Use Them](https://cmap.ihmc.us/publications/researchpapers/theoryunderlyingconceptmaps.pdf) de Joseph D. Novak y Alberto J. Ca√±as."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}